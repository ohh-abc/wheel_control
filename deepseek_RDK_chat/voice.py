#from bot import Bot
#gpt = Bot(model='gpt-4o-mini',tools=[],prompt="ä½ æ˜¯æˆ‘çš„å·¥ä½œåŠ©æ‰‹ã€‚",debug=True)
import os  
from dotenv import load_dotenv  
import io  
import azure.cognitiveservices.speech as speechsdk  
from openai import OpenAI
import time  
import datetime  
import threading  
import json, ast  
import re  # æ–°å¢æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—
import requests  
from io import BytesIO  
import tempfile  
#import pyaudio  
from tools import *
  
load_dotenv("1.env")  
client = OpenAI(api_key=os.environ["api_key"], base_url=os.environ["base_url"])
#client = OpenAI(api_key="1", base_url="http://localhost:11434/v1") 
Azure_speech_key = os.environ["Azure_speech_key"]  
Azure_speech_region = os.environ["Azure_speech_region"]  
Azure_speech_speaker = os.environ["Azure_speech_speaker"]  
WakeupWord = os.environ["WakeupWord"]  
WakeupModelFile = os.environ["WakeupModelFile"]  

messages = []  

# è®¾ç½®Azureè¯­éŸ³æœåŠ¡
speech_key = Azure_speech_key  
service_region = Azure_speech_region  
speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)  
speech_config.speech_synthesis_language = "zh-CN"  
speech_config.speech_recognition_language = "zh-CN"  
lang = "zh-CN"  
speech_config.speech_synthesis_voice_name = Azure_speech_speaker  
speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)  
connection = speechsdk.Connection.from_speech_synthesizer(speech_synthesizer)  
connection.open(True)  
model = speechsdk.KeywordRecognitionModel(WakeupModelFile)  
keyword = WakeupWord  
audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)  
auto_detect_source_language_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(languages=["ja-JP", "zh-CN"])  
speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config,  
                                               auto_detect_source_language_config=auto_detect_source_language_config)  
unknownCount = 0  
sysmesg = {"role": "system", "content": os.environ["sysprompt_zh-CN"]}  
tts_sentence_end = [ ".", "!", "?", ";", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "\n" ]

isListenning = False

# æ–°å¢ï¼šæ–‡æœ¬æ¸…æ´—å‡½æ•°
def clean_tts_text(text):
    """æ¸…é™¤æ–‡æœ¬ä¸­ä¸åº”è¢«æœ—è¯»çš„ç‰¹æ®Šç¬¦å·"""
    if not isinstance(text, str):
        return str(text)
    
    # ç§»é™¤Markdownæ ¼å¼
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # **å¼ºè°ƒ** â†’ å¼ºè°ƒ
    text = re.sub(r'_(.*?)_', r'\1', text)         # _æ–œä½“_ â†’ æ–œä½“
    text = re.sub(r'`(.*?)`', r'\1', text)         # `ä»£ç ` â†’ ä»£ç 
    
    # æ›¿æ¢ç‰¹æ®Šç¬¦å·
    symbol_map = {
        r'\*': ' ',
        r'_': ' ',
        r'#': 'ï¼Œ',
        r'\[': ' ',
        r'\]': ' ',
        r'\{': ' ',
        r'\}': ' ',
        r'\(': ' ',
        r'\)': ' ',
        r'<': ' ',
        r'>': ' ',
        r'\|': 'ï¼Œ',
        r'~': ' ',
        r'\^': ' ',
        r'\\': ' ',
        r'/': ' ',
        r'@': ' ',
        r'\+': 'åŠ ',
        r'=': 'ç­‰äº'
    }
    
    for pattern, replacement in symbol_map.items():
        text = re.sub(pattern, replacement, text)
    
    # å¤„ç†æ•°å­—ï¼ˆç®€å•ä¸­æ–‡è¯»æ³•ï¼‰
    def num_to_chinese(match):
        num = match.group(0)
        if num.isdigit():
            # ç®€å•è½¬æ¢ï¼Œå¤æ‚æƒ…å†µå¯ä»¥ä½¿ç”¨ç¬¬ä¸‰æ–¹åº“
            chinese_digits = ['é›¶', 'ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹']
            return ''.join(chinese_digits[int(d)] for d in num)
        return num
    
    text = re.sub(r'\d+', num_to_chinese, text)
    
    # åˆå¹¶å¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def display_text(s):
    print(s)
    
def speech_to_text():  
    global unknownCount  
    global lang, isListenning  
    print("è¯·è¯´è¯...")  
    try:
        result = speech_recognizer.recognize_once_async().get()  
        if result.reason == speechsdk.ResultReason.RecognizedSpeech:  
            unknownCount = 0  
            isListenning = False
            return result.text  
        elif result.reason == speechsdk.ResultReason.NoMatch:  
            isListenning = False
            unknownCount += 1  
            error = os.environ.get(f"sorry_{lang}", "æŠ±æ­‰ï¼Œæˆ‘æ²¡å¬æ¸…æ¥š")  
            text_to_speech(error)  
            return '...'  
        elif result.reason == speechsdk.ResultReason.Canceled:  
            isListenning = False
            return "è¯­éŸ³è¯†åˆ«å·²å–æ¶ˆ"
    except Exception as e:
        print(f"è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
        return "è¯­éŸ³è¯†åˆ«é”™è¯¯"
    

def getVoiceSpeed():  
    return 17  
  
def text_to_speech(text, _lang=None):  
    global lang  
    try:  
        result = buildSpeech(text).get()  
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:  
            print("æ–‡æœ¬è½¬è¯­éŸ³æˆåŠŸ")  
            return "æˆåŠŸ"  
        else:  
            print(f"è¯­éŸ³åˆæˆé”™è¯¯: {result}")  
            return "å¤±è´¥"  
    except Exception as ex:  
        print(f"è¯­éŸ³åˆæˆå¼‚å¸¸: {ex}")  
        return "é”™è¯¯"  
        
def buildSpeech(text, _lang=None):
    # æ¸…æ´—æ–‡æœ¬
    cleaned_text = clean_tts_text(text)
    
    voice_lang = lang  
    voice_name = Azure_speech_speaker
    ssml_text = f'''  
        <speak xmlns="http://www.w3.org/2001/10/synthesis" 
               xmlns:mstts="http://www.w3.org/2001/mstts" 
               version="1.0" 
               xml:lang="{lang}">
            <voice name="{voice_name}">
                <lang xml:lang="{voice_lang}">
                    <prosody rate="{getVoiceSpeed()}%">
                        {cleaned_text}
                    </prosody>
                </lang>
            </voice>
        </speak>  
    '''  
    print(f"[è¯­éŸ³åˆæˆ] {cleaned_text}")  
    return speech_synthesizer.speak_ssml_async(ssml_text)
  
def generate_text(prompt):  
    global messages  
    messages.append({"role": "user", "content": prompt})  
    tools = getTools()  
    collected_messages = []
    last_tts_request = None

    result = ''
    function_list = []
    
    try:
        response_gen = client.chat.completions.create(
            model="deepseek-chat",
            messages=[sysmesg] + messages[-20:],
            tools=tools,
            stream=False
        )
        response_message = response_gen.choices[0].message
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if response_message.tool_calls:
            tool_calls = response_message.tool_calls
            function_results = []
            
            for tool_call in tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                function_to_call = globals().get(function_name)
                
                if not function_to_call:
                    error_msg = f"âš ï¸ å‡½æ•°ä¸å­˜åœ¨: {function_name}"
                    print(error_msg)
                    function_results.append(error_msg)
                    continue
                    
                try:
                    print(f"ğŸ› ï¸ è°ƒç”¨å‡½æ•°: {function_name}({function_args})")
                    result = function_to_call(**function_args)
                    function_results.append(str(result))
                    print(f"âœ… å‡½æ•°ç»“æœ: {result}")
                except Exception as e:
                    error_msg = f"âš ï¸ {function_name}æ‰§è¡Œé”™è¯¯: {str(e)}"
                    print(error_msg)
                    function_results.append(error_msg)
            
            # åˆå¹¶ç»“æœå¹¶æ·»åŠ åˆ°å¯¹è¯å†å²
            combined_result = "\n".join(function_results)
            messages.append({
                "role": "assistant", 
                "content": f"ã€å·¥å…·è°ƒç”¨ç»“æœã€‘\n{combined_result}"
            })
            
            # è¯­éŸ³æ’­æŠ¥ç»“æœ
            last_tts_request = buildSpeech(combined_result)
            result = combined_result
        
        # å¤„ç†æ™®é€šå›å¤
        elif response_message.content and response_message.content != '':
            result = response_message.content
            messages.append({"role": "assistant", "content": result})
            last_tts_request = buildSpeech(result)
            
    except Exception as e:
        error_msg = f"âš ï¸ ç”Ÿæˆæ–‡æœ¬æ—¶å‡ºé”™: {str(e)}"
        print(error_msg)
        result = error_msg
        last_tts_request = buildSpeech("æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™äº†")
    
    # ç­‰å¾…è¯­éŸ³åˆæˆå®Œæˆ
    if last_tts_request:
        try:
            last_tts_request.get()
        except Exception as e:
            print(f"âš ï¸ è¯­éŸ³åˆæˆç­‰å¾…é”™è¯¯: {str(e)}")
    
    return result

def Get_Chat_Deployment():  
    return os.environ.get("Azure_OPENAI_Chat_API_Deployment", "default-deployment")  

def recognized_cb(evt):  
    result = evt.result  
    if result.reason == speechsdk.ResultReason.RecognizedKeyword:  
        print("è¯†åˆ«åˆ°å…³é”®è¯: {}".format(result.text))  
    global done  
    done = True  

def canceled_cb(evt):  
    result = evt.result  
    if result.reason == speechsdk.ResultReason.Canceled:  
        print('å·²å–æ¶ˆ: {}'.format(result.cancellation_details.reason))  
    global done  
    done = True  
   
def start_recognition():  
    global unknownCount, isListenning
    print("è¯­éŸ³åŠ©æ‰‹å¯åŠ¨ä¸­...")
    
    # åˆå§‹é—®å€™
    first = os.environ.get(f"welcome_{lang}", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯è¯­éŸ³åŠ©æ‰‹")
    display_text(first) 
    text_to_speech(first)
    
    while True:  
        keyword_recognizer = speechsdk.KeywordRecognizer()  
        keyword_recognizer.recognized.connect(recognized_cb)  
        keyword_recognizer.canceled.connect(canceled_cb) 
        
        # æ’­æ”¾å”¤é†’æç¤º
        wake_prompt = os.environ.get(f"listen_{lang}", "ç­‰å¾…å”¤é†’è¯")
        display_text(wake_prompt)
        text_to_speech(wake_prompt)
        
        isListenning = True
        result_future = keyword_recognizer.recognize_once_async(model)  
        while True:  
            result = result_future.get()
            if result.reason == speechsdk.ResultReason.RecognizedKeyword:
                print("âœ… è¯†åˆ«åˆ°å”¤é†’è¯")
                isListenning = False
                if getPlayerStatus() == 'playing':
                    pauseplay()  # è¢«å”¤é†’åæš‚åœéŸ³ä¹
                break
            time.sleep(0.1)  
            
        # å”¤é†’åå“åº”
        wake_response = os.environ.get(f"wake_{lang}", "æˆ‘åœ¨å¬ï¼Œè¯·è®²")
        display_text(wake_response)  
        text_to_speech(wake_response)  
          
        # å¯¹è¯å¾ªç¯
        while unknownCount < 2:
            isListenning = True
            user_input = speech_to_text()
            
            # å¤„ç†è¯†åˆ«é—®é¢˜
            if user_input == '...':
                continue
                
            print(f"ç”¨æˆ·: {user_input}")  
            display_text(f"ç”¨æˆ·: {user_input}")  
            
            # ç”Ÿæˆå“åº”
            response = generate_text(user_input)
            
            # æ£€æŸ¥æ˜¯å¦åº”ç»“æŸå¯¹è¯
            if response.strip().lower() in ["é€€å‡º", "ç»“æŸ", "å†è§"]:
                break
                
            # æ£€æŸ¥éŸ³ä¹çŠ¶æ€
            if getPlayerStatus() == 'playing':
                break
          
        # ç»“æŸå¯¹è¯
        bye_text = os.environ.get(f"bye_{lang}", "å†è§")  
        display_text(bye_text) 
        text_to_speech(bye_text)  
        
        unknownCount = 0  
        time.sleep(0.1)  

if __name__ == "__main__":
    try:
        start_recognition()
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"âš ï¸ ä¸»ç¨‹åºé”™è¯¯: {str(e)}")
        text_to_speech("æŠ±æ­‰ï¼Œç³»ç»Ÿé‡åˆ°ä¸¥é‡é”™è¯¯")